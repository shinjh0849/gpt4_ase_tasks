{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f8aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "openai.api_key = ''\n",
    "dataset = load_dataset(\"openai_humaneval\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26dd4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-4\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\",\n",
    "         \"content\": \"You are a helpful code generation model \\\n",
    "         that can generate source code for a Python function \\\n",
    "         given its header and comments describing its purpose.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7626a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nl_to_code():\n",
    "    with open ('he_sims.jsonl') as f:\n",
    "        json_list = list(f)\n",
    "    test_dict = []\n",
    "    for json_str in json_list:\n",
    "        result = json.loads(json_str)\n",
    "        test_dict.append(result)\n",
    "    \n",
    "    write_file = open(\"humaneval_in_context.txt\", \"w\")\n",
    "    group_size = 4\n",
    "    groups = zip(*(iter(dataset),) * group_size)\n",
    "    for test, group in zip(test_dict, groups):        \n",
    "        prompt = f\"\"\"\n",
    "        Given 3 pairs of Python code examples and answers, \\\n",
    "        generate Python source code for 4 functions' bodies, \\\n",
    "        given Python code (surrounded by ???) containing imports, \\\n",
    "        the function's header, and comments describing the function's \\\n",
    "        purpose along with sample test cases & expected results.\\\n",
    "        Output only the Python function body (no header, comments, or imports) \\ \n",
    "        on exactly one line. \\\n",
    "        Text 1: {test['nl'][0]} \\\n",
    "        Code 1: {test['code'][0]} \\\n",
    "        Text 2: {test['nl'][1]} \\\n",
    "        Code 2: {test['code'][1]} \\\n",
    "        Text 3: {test['nl'][2]} \\\n",
    "        Code 3: {test['code'][2]} \\\n",
    "        Code 1: ???{group[0]['prompt']}??? \\\n",
    "        Code 2: ???{group[1]['prompt']}??? \\\n",
    "        Code 3: ???{group[2]['prompt']}??? \\\n",
    "        Code 4: ???{group[3]['prompt']}??? \\\n",
    "        Answer 1: \\\n",
    "        Answer 2: \\\n",
    "        Answer 3: \\\n",
    "        Answer 4: \\\n",
    "        \"\"\"\n",
    "        responses = get_completion(prompt).splitlines()\n",
    "        for response in responses:\n",
    "            if len(response) != 0:\n",
    "                write_file.write(response + '\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83346b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_to_code()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
